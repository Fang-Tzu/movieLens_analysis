---
title: "Report - movieLens dataset analysis"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=F, warning=F)
```

## Introduction

> Note: The sources are available [here](https://github.com/redroy44/movieLens_analysis).

This is a report on the movieLens dataset available [here](https://grouplens.org/datasets/movielens/). MovieLens itself is a research site run by GroupLens Research group at the University of Minnesota. An interesting thing to notice is that the first automated recommender system was developed there in 1993.

### Objectives

The movieLens dataset is most often used for the purpose of recommender systems. Their purpose is to predict user movie ratings based on other users' ratings. In other words we expect that user with similar taste will tend to rate movies with high correlation. 

However, in this analysis we will try to explore the movies themselves. Hopefully it will give us an interesting insight into the history of cinematography.

### Packages used

For this analysis the Microsoft R Open distribution was used. The reason for this was its multithreaded performance as described [here](https://mran.microsoft.com/documents/rro/multithread/). Most of the packages that were used come from the [tidyverse](http://tidyverse.org/) - a collection of packages that share common philosophies of tidy data. The tidytext and wordcloud packages were used for some text processing. Finally the doMC package was used to embrace the multithreading in some of the custom functions which will be described later. 

> Note: doMC package is not available on Windows. Use doParallel package instead.

```{r packages, results='hide'}
# Load the packages -------------------------------------------------------
library(checkpoint)
checkpoint("2016-11-15", auto.install.knitr=T)
library(tidyverse)
library(lubridate)
library(stringr)
library(rvest)
library(XML)
library(tidytext)
library(wordcloud)
library(doMC)
registerDoMC(cores = 8)
set.seed(29082012)
```

The output of sessionInfo() is placed here for reproducibility purposes.
```{r, echo=T}
# Print Session Information
sessionInfo()
```

## Dataset Description

The dataset is avaliable in several snapshots. The ones that were used in this analysis were Latest Datasets - both full and small (for testing purposes). They were last updated in October 2016.

First the data was automatically downloaded and unzipped. 

###Dataset Download

First the data was automatically downloaded and unzipped. Although it is generally done only once during the analysis, it makes the reproducibility so much easier and less painful.

```{r, echo=T}
url <- "http://files.grouplens.org/datasets/movielens/"
dataset_small <- "ml-latest-small"
dataset_full <- "ml-latest"
data_folder <- "data"
archive_type <- ".zip"

# Choose dataset version
dataset <- dataset_full
dataset_zip <- paste0(dataset, archive_type)

# Download the data and unzip it
if (!file.exists(file.path(data_folder, dataset_zip))) {
  download.file(paste0(url, dataset_zip), file.path(data_folder, dataset_zip))
}
unzip(file.path(data_folder, dataset_zip), exdir = data_folder, overwrite = F)

# Display the unzipped files
list.files('data/', recursive=T)
```
### Loading the Dataset

The dataset is split into four files (genome-scores.csv and genome-tags.csv were omitted for this analysis)- movies.csv, ratings.csv, links.csv and tags.csv. We will iteratively load the files into the workspace using read_csv() function and assign variable names accordingly. The read_csv() function is very convenient because it automagically guesses column types based on the first thousand rows. And more importantly it never converts strings to factors. Never. 

Finally we will check object sizes to see how big is the dataset.
```{r, echo=T}
dataset_files <- c("movies", "ratings", "links", "tags")
suffix <- ".csv"

for (f in dataset_files) {
  path <- file.path(data_folder, dataset, paste0(f, suffix))
  assign(f, read_csv(path))
  print(paste(f, "object size is", format(object.size(get(f)),units="Mb")))
}
```

The biggest data frame is ratings - it contains movie ratings from movieLens users. Next we will see what kind of data we deal with.

## Data Cleaning

In this section we will take the first look at the loaded data frames. We will also perform necessary cleaning and some transformations so that the data better suits our needs. First, let's look at the ratings table.

```{r}
# Clean ratings
glimpse(ratings)
```

We have 24 millions rows and 4 columns. It seems that only timestamp column need to be parsed. We will create new data frame that we will work on and preserve the original data frame (treat it as read-only).

```{r}
ratings_df <- tbl_df(ratings) %>%
  mutate(timestamp = as_datetime(timestamp))
```
Next, let's check if there are any missing values.
```{r}
summary(ratings_df)
```



```{r}
# Clean movies
# TODO make genres a factor?
glimpse(movies)
movies_df <- tbl_df(movies) %>%
  mutate(title = str_trim(title)) %>% # trim whitespaces
  extract(title, c("title_tmp", "year"), regex = "^(.*) \\(([0-9 \\-]*)\\)$", remove = F) %>% # split title to title, year
  mutate(year = if_else(str_length(year) > 4, as.integer(str_split(year, "-", simplify = T)[1]), as.integer(year))) %>% # for series take debut date
  mutate(title = if_else(is.na(title_tmp), title, title_tmp)) %>% # replace title NA's with original title
  select(-title_tmp)  %>%# drop title1 column
  mutate(genres = if_else(genres == "(no genres listed)", `is.na<-`(genres), genres)) # generic function to turn (no genres listed) to NA
```
```{r}
# Check NA's
na_movies <- movies_df %>%
  filter(is.na(title) | is.na(year)) %>%
  print
```
```{r}
# Clean tags
glimpse(tags)
tags_df <- tbl_df(tags) %>%
  mutate(timestamp = as_datetime(timestamp))
```
```{r}
summary(movies_df)

```

```{r}
genres <- movies_df %>%
  separate_rows(genres, sep = "\\|") %>%
  group_by(genres) %>%
  summarise(number = n()) %>%
  arrange(desc(number))
  #knitr::kable(genres, caption = "List of Genres")
```

## Data Exploration

### Q1
```{r q1}
# Number of movies per year/decade
movies_per_year <- movies_df %>%
  na.omit() %>%
  select(movieId, year) %>%
  group_by(year) %>%
  summarise(count = n())

# fill missing years
movies_per_year <- movies_per_year %>%
  complete(year = full_seq(year, 1), fill = list(count = 0))

# TODO turn to ggvis!
movies_per_year %>%
  #filter(year > 2010) %>%
  ggplot(aes(x = year, y = count)) +
  geom_line(color="blue")
```

### Q2
```{r q2}
# Genres popularity per year
genres_popularity <- movies_df %>%
  na.omit() %>%
  select(movieId, year, genres) %>%
  separate_rows(genres, sep = "\\|") %>%
  mutate(genres = as.factor(genres)) %>%
  group_by(year, genres) %>%
  summarise(number = n()) %>%
  complete(year = full_seq(year, 1), genres, fill = list(number = 0))

# Most popular genres
genres_top <- genres_popularity %>%
  group_by(genres) %>%
  summarise(number = sum(number)) %>%
  arrange(desc(number)) %>%
  top_n(10, number)
  

# TODO turn to ggvis!
genres_popularity %>%
  filter(year > 1930) %>%
  filter(genres %in% genres_top$genres) %>%
  ggplot(aes(x = year, y = number)) +
    geom_area(aes(fill=genres), position = "fill") + 
    scale_fill_brewer(palette = "Paired") 
```

### Q3 {.tabset .tabset-fade .tabset-pills}
Question 3 text
```{r q3-1, warning=T, message=T}
# Tags for genres
genres_tags <- movies_df %>%
  na.omit() %>%
  select(movieId, year, genres) %>%
  separate_rows(genres, sep = "\\|") %>%
  inner_join(tags_df, by = "movieId") %>%
  select(genres, tag) %>%
  #distinct() %>%
  group_by(genres) %>%
  nest()
```

#### Action

```{r q3-2, warning=T, message=T}
# plot wordcloud per genre
genre<-"Action"
genre_words <- genres_tags %>%
  filter(genres == genre) %>%
  unnest() %>%
  mutate(tag = str_to_lower(tag, "en")) %>%
  anti_join(tibble(tag=c(tolower(genre)))) %>%
  count(tag)

  wordcloud(genre_words$tag, genre_words$n, max.words = 10, colors=brewer.pal(8, "Dark2"))

```

#### Comedy

```{r q3-3, warning=T, message=T}
# plot wordcloud per genre
genre<-"Comedy"
genre_words <- genres_tags %>%
  filter(genres == genre) %>%
  unnest() %>%
  mutate(tag = str_to_lower(tag, "en")) %>%
  anti_join(tibble(tag=c(tolower(genre)))) %>%
  count(tag)

  wordcloud(genre_words$tag, genre_words$n, max.words = 10, colors=brewer.pal(8, "Dark2"))

```


### Q4
```{r q4}
# average rating for a movie

avg_rating <- ratings_df %>%
  inner_join(movies_df, by = "movieId") %>%
  na.omit() %>%
  select(movieId, title, rating, year) %>%
  group_by(movieId, title, year) %>%
  summarise(count = n(), mean = mean(rating), min = min(rating), max = max(rating)) %>%
  ungroup() %>%
  arrange(count, desc(mean)) %>%
  print
```
```{r, warning=T, message=T}
# Lower bound of Wilson score confidence interval for a Bernoulli parameter
# http://www.evanmiller.org/how-not-to-sort-by-average-rating.html
# movies with the same mean but more reviews get higher score
ci_lower <- function(pos, n, confidence) {
  z = qnorm(1-(1-confidence)/2)
  phat = pos
  return (phat + z*z/(2*n) - z * sqrt((phat*(1-phat)+z*z/(4*n))/n))/(1+z*z/n)
}

avg_rating <- avg_rating %>%
  mutate(score = ci_lower(mean/5, count, 0.95)) %>%
  arrange(desc(score))

# find best movie of a decade based on score
# heavily dependent on the number of reviews
best_per_decade <- avg_rating %>%
  filter(count > 2) %>% # at least the median number of reviews (3)
  mutate(decade = year  %/% 10 * 10) %>%
  arrange(year, desc(score)) %>%
  group_by(decade) %>%
  summarise(title = first(title), score = first(score), mean = first(mean), count = first(count))
print(best_per_decade)
```

### Q5
```{r q5}
genres_rating <- movies_df %>%
  na.omit() %>%
  select(movieId, year, genres) %>%
  inner_join(ratings_df, by = "movieId") %>%
  select(-timestamp, -userId) %>%
  mutate(decade = year  %/% 10 * 10) %>%
  separate_rows(genres, sep = "\\|") %>%
  group_by(year, genres) %>%
  summarise(count = n(), avg_rating = mean(rating)) %>%
  ungroup() %>%
  mutate(score = ci_lower(avg_rating/5, count, 0.95)) %>%
  arrange(year)

# TODO turn to ggvis!
genres_rating %>%
  filter(genres %in% genres_top$genres) %>%
  ggplot(aes(x = year, y = score)) +
    geom_line(aes(group=genres, color=genres)) +
    geom_smooth(aes(group=genres, color=genres)) +
    facet_wrap(~genres)
```

## Web Scraping
```{r , results='hold'}
# source utility functions
source(file = "functions.R")

imdb_url = "http://www.imdb.com/title/tt"

imdb_df <- movies_df %>%
  inner_join(links, by = "movieId") %>%
  select(-tmdbId) %>%
  mutate(link = paste0(imdb_url, imdbId))

# Quick check
get_cast(c("http://www.imdb.com/title/tt0114709", "http://www.imdb.com/title/tt0076759"))
get_budget(c("http://www.imdb.com/title/tt0114709", "http://www.imdb.com/title/tt0076759"))
get_director(c("http://www.imdb.com/title/tt0114709", "http://www.imdb.com/title/tt0076759"))
get_time(c("http://www.imdb.com/title/tt0114709", "http://www.imdb.com/title/tt0076759"))
```

### Q6
```{r q6, cache=T}
system.time({
imdb_df1 <- imdb_df %>%
  top_n(1) %>%
  mutate(time = get_time(link)) %>%
  mutate(director = get_director(link)) %>%
  mutate(budget = get_budget(link)) %>% # Will be sparse. Or not?
  mutate(cast = get_cast(link))
})
```
